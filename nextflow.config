/*
 * ==================================================
 * EPSCoR-NASA Microbiome Pipeline configuration file
 * Version: v0.1
 * Author: Kanishka Manna & Hans Vasquez-Gross
 * Date: 2025-04-18
 * ==================================================
 */

/*
 * ---------------- Manifest information --------------- *
 */


/* 
 * ---------------- Define parameters ---------------- *
 */
params {

    // ----- Execution parameters ----- //

    // Global options:
    help = false
    
    samplesheet = null
    
    output = "${baseDir}/results"
    
    time = ""
    //low_mem = "8 GB"
    //medium_mem = "16 GB"
    //high_mem = "32 GB"
    //low_cpu = 1
    //medium_cpu = 2
    //high_cpu = 4


    // ---------- Process specific parameters ---------- //
    
    // KNEADING_DATA:
    
        /*
            NOTE: Please download the KneadData database by `kneaddata_database` command. 
                    You can also make a custom database.
                    See KneadData GitHub repo (https://github.com/biobakery/kneaddata?tab=readme-ov-file) 
                    for more information.
         */
    kneaddata_db = null
    
    kneaddata_sequencer_source = "NexteraPE" // Options: NexteraPE, TruSeq2, TruSeq3, none

        /* 
        NOTE: For total resources used for 1 given kneaddata sample run, is "kneaddata_threads x kneaddata_processes".
                In the default case below 4 x 2 = 8 total threads
                This is fine for local mode, but if you are running to a cluster, 
                be sure to adjust the cluster settings for "high" to match.
        */
    kneaddata_threads = 4
    
    kneaddata_processes = 1
    
    kneaddata_time = ""
    
    kneaddata_mem = "8 GB"
    
    kneaddata_extra = ""


    // TAXONOMIC_PROFILING:

        /*
            NOTE: Please download the database by `metaphlan --install --index <INDEX-BUILD> --bowtie2db <DIR>` command
                    
                    You can also download from Segata Lab FTP: 
                    http://cmprod1.cibio.unitn.it/biobakery4/metaphlan_databases/?C=M;O=D
                    
                    For more information, please review MetaPhlan GitHub readme 
                    (https://github.com/biobakery/MetaPhlAn/wiki/MetaPhlAn-4.1)
                
            !!! CAUTION: Please do not download the latest MetaPhlAn database. 
                The BioBakery developers have confirmed that it does not work well with HUMAnN 3.9.
        */
    metaphlan_db = null

    // 
        
        // NOTE: For available indexes, see Segata Lab FTP: http://cmprod1.cibio.unitn.it/biobakery4/metaphlan_databases/?C=M;O=D
    metaphlan_index = "mpa_vJun23_CHOCOPhlAnSGB_202403"
    
    metaphlan_nproc = 4
    
    metaphlan_time = ""
    
    metaphlan_mem = "16 GB"
    
    metaphlan_extra = ""


    // FUNCTIONAL_PROFILING:

        /*
            NOTE: Please download the database for BOTH nucleotide and protein by
                 `humann_databases --download <DATABASE> <BUILD> <DIRECTORY>` command
                    
                For more information, please review HUMAnN GitHub readme 
                    (https://github.com/biobakery/humann?tab=readme-ov-file#5-download-the-databases)
        */
    humann_nucleotide_db = null
    humann_protein_db = null
    
    humann_pathway_db = "metacyc" // Options: 'metacyc' or 'unipathways'
    
    humann_threads = 4
    
    humann_time = ""
    humann_mem = ""
    humann_extra = ""


    // Consensus pathway analysis:

    goterm_db = null

    goterm_cpu = 2
    goterm_mem = "16 GB"

    cpa_cpu = 2
    cpa_mem = "16 GB"


    // Descriptive profiling analysis:
    humann_renorm_units = "cpm" // Options: 'relab' (relative abundance), 'cpm' (counts per million)
    
    norm_path_cpu = 2
    norm_path_mem = "16 GB"

    join_path_cpu = 1
    join_path_mem = "8 GB"

    desc_cpu = 1
    desc_mem = "8 GB"



}



/*
 * --------------- Execution profiles for environments --------------- *
 */

profiles {

    // Local-workstation execution profile
    local {

        process.executor = 'local'
        conda.enabled = true
        conda.channels = ['defaults', 'conda-forge', 'bioconda', 'biobakery']
        conda.createTimeout = '20 min'
        
        process {

            withLabel: 'kneaddata_conda'    { conda = "assets/kneaddata.yaml" }
            withLabel: 'metaphlan_conda'    { conda = "assets/metaphlan.yaml" }
            withLabel: 'humann_conda'       { conda = "assets/humann.yaml" }
            withLabel: 'go_term_conda'      { conda = "assets/goterm.yaml" }
            withLabel: 'cpa_conda'          { conda = "assets/cpa.yaml" }
            withLabel: 'desc_conda'         { conda = "assets/desc.yaml" }
            withLabel: 'multiqc_conda'      { conda = "assets/multiqc.yaml" }

        }

        // Load `local.config` when running locally
        includeConfig 'conf/local.config'
    }


    
    // HPC execution profile
    cluster {
        process.executor = 'slurm'
        conda.enabled = true
        conda.channels = ['defaults', 'conda-forge', 'bioconda', 'biobakery']
        conda.createTimeout = '20 min'

        process {

           withLabel: 'kneaddata_conda'     { conda = "assets/kneaddata.yaml" }
           withLabel: 'metaphlan_conda'     { conda = "assets/metaphlan.yaml" }
           withLabel: 'humann_conda'        { conda = "assets/humann.yaml" }
           withLabel: 'go_term_conda'       { conda = "assets/goterm.yaml" }
           withLabel: 'cpa_conda'           { conda = "assets/cpa.yaml" }
           withLabel: 'desc_conda'          { conda = "assets/desc.yaml" }
           withLabel: 'multiqc_conda'       { conda = "assets/multiqc.yaml" }
        }

        // Load `cluster.config` when running on HPC
        includeConfig 'conf/cluster.config'
    }



    // Local execution profile using containers
    //test {
    //    process.executor = 'local'
    //    docker.enabled = true
    //    docker.runOptions = '--memory=32G -u \$(id -u):\$(id -g)'

    //    process {
    //        withLabel: 'kneaddata_docker' {
    //            container = "community.wave.seqera.io/library/fastqc_kneaddata:292d283c4c7b5157"
    //        }

    //        withLabel: 'metaphlan_docker' {
    //            container = "community.wave.seqera.io/library/metaphlan:4.2.2--644dc6928ffa70c6"
    //        }

    //        withLabel: 'humann_docker' {
    //            container = "community.wave.seqera.io/library/humann:3.9--b616b2952dd13a24"
    //        }

    //        withLabel: 'go_term_docker' {
    //            container = "docker.io/kmanna123/goterm:latest"
    //        }

    //        withLabel: 'cpa_docker' {
    //            container = "docker.io/kmanna123/cpa:latest"
    //        }

    //        withLabel: 'multiqc_docker' {
    //            container = "community.wave.seqera.io/library/multiqc:1.29--e3ef3b42c5f9f0da"
    //        }
    //    }

        // Load `base.config` when running locally
        //includeConfig 'conf/base.config'
    //    includeConfig 'conf/test.config'
    //}

}


/*
 * --------------- Global Shell settings --------------- *
 */
// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']


/*
 * --------------- Nextflow related settings --------------- *
 */

// Cleaning up Nextflow's work directory
cleanup = false

// DAG
dag {
    enabled = true
    file = 'dag-epscor_nasa_pipeline.html'
    overwrite = true
}

// Execution report
report {
    enabled = true
    file = 'report-epscor_nasa_pipeline.html'
    overwrite = true
}

// Timeline
timeline {
    enabled = true
    overwrite = true
}

// Workflow
workflow {
    onComplete = {
        """
        Pipeline execution summary
        ---------------------------
        Completed at: ${workflow.complete}
        Duration    : ${workflow.duration}
        Success     : ${workflow.success}
        workDir     : ${workflow.workDir}
        exit status : ${workflow.exitStatus}
        """.stripIndent()
    }
}


/*
=====================
    Help Message    
=====================
*/

params.help_message = """

        ------
        Usage:
        ------

        ```
        nextflow main.nf \\
            -profile <PROFILE> \\
            --samplesheet /PATH/to/INPUT.csv \\
            --output /PATH/to/OUTPUT_DIR \\
            --kneaddata_db /PATH/to/KneadData/Database \\
            --metaphlan_db /PATH/to/MetaPhlAn/Database
            --humann_nucleotide_db /PATH/to/HUMAnN/Nucleotide/Database \\
            --humann_protein_db /PATH/to/HUMAnN/Protein/Database \\
            --humann_pathway_db PATHWAY_DB \\
            --goterm_db /PATH/to/GOterms/Database
        ```

        ------------------
        parameter options:
        ------------------
            * -profile : Specify the profile to use for running the pipeline in local or on the HPC. 
                This can be set to the following: 
                local: To run the pipeline on local machine, uses separate conda environment for each process.
                cluster: To run the pipeline on HPC, uses separate conda environment for each process.

            * --samplesheet : Path to a CSV file where each row specifies the sample name and the file paths to paired-end FASTQ files (R1 and R2), separated by commas.

            * --output : Path to the output directory where results will be saved.

        // KneadData paramters:

            * --kneaddata_db : Path to the directory where the KneadData database is located.

            * --kneaddata_threads : Specify the number of threads. (DEFAULT: 4)

            * --kneaddata_processes : Specify the number of processes. (DEFAULT: 2)

            * --kneaddata_extra : User specified extra parameter option. (OPTIONAL)

        // MetaPhlAn parameters:

            * --metaphlan_db : Path to the directory where the MetaPhlAn database is located.

            * --metaphlan_nproc : Specify the number of processes. (DEFAULT: 4)

            * --metaphlan_extra : User specified extra parameter option. (OPTIONAL)
        
        // HUMAnN parameters:
            
            * --humann_nucleotide_db : Path to the directory where the HUMAnN Nucleotide database is located

            * --humann_protein_db : Path to the directory where the HUMAnN Protein database is located

            * --humann_pathway_db : Specify the database to use for pathway {metacyc, unipathways} computations (default: metacyc)

            * --humann_threads : Specify the number of threads. (DEFAULT: 4)

            * --humann_extra : User specified extra parameter option. (OPTIONAL)
        
        // GO-terms parameter:

            * --goterm_db : Path to the directory where the GOTerms Database will be downloaded/located.
    """
    .stripIndent()
